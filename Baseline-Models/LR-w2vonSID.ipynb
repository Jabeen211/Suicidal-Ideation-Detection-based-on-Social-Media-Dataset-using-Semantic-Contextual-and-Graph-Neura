{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1PmB0o9HNpJ6BONJcboxUAlPH6XkkXSc0","timestamp":1696574238999},{"file_id":"11LZSpO4bJjsjhFNGu1gS21AjfPHorceN","timestamp":1695285825118},{"file_id":"1AajmpsZUd6_qs_7sXZzBaKU2riIDyCgF","timestamp":1695285143859}],"gpuType":"T4","authorship_tag":"ABX9TyMEqlMydJXHxEm5TqI9/1y3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# Naive Bayes Classification for SID"],"metadata":{"id":"8s0LTac93X6l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-QNFX0iET5ub","executionInfo":{"status":"ok","timestamp":1696574338764,"user_tz":-360,"elapsed":40102,"user":{"displayName":"Suraia Jabeen","userId":"07369339192617605376"}},"outputId":"ab206b9d-360c-4276-d857-98d72409c4f4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Install necessary libraries\n","!pip install nltk scikit-learn\n","\n","import pandas as pd\n","import numpy as np\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer, WordNetLemmatizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","from sklearn.preprocessing import MinMaxScaler\n","from gensim import models\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","# Load your dataset (replace 'your_dataset.csv' with your dataset file)\n","path = \"/content/drive/MyDrive/Saddam_Sir/Thesis/Dataset/Merged-file-_1_.csv\"\n","df = pd.read_csv(path )\n","\n","# Preprocess text data\n","stop_words = set(stopwords.words('english'))\n","stemmer = PorterStemmer()\n","lemmatizer = WordNetLemmatizer()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8t_F7EkPskcJ","executionInfo":{"status":"ok","timestamp":1696574353078,"user_tz":-360,"elapsed":9015,"user":{"displayName":"Suraia Jabeen","userId":"07369339192617605376"}},"outputId":"1cdfc174-57e3-483c-9ce6-1b938c34cc6a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]}]},{"cell_type":"code","source":["pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G3-YazTl-dDl","executionInfo":{"status":"ok","timestamp":1696574375127,"user_tz":-360,"elapsed":17883,"user":{"displayName":"Suraia Jabeen","userId":"07369339192617605376"}},"outputId":"899a69b6-f87e-4d3b-ea92-1df364f3ed60"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers<0.15,>=0.14 (from transformers)\n","  Downloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.14.0 transformers-4.34.0\n"]}]},{"cell_type":"code","source":["def preprocess_text(text):\n","    # Tokenization\n","    words = nltk.word_tokenize(str(text).lower())\n","\n","    # Remove stopwords and non-alphanumeric characters\n","    filtered_words = [word for word in words if word.isalnum() and word not in stop_words]\n","\n","    # Stemming and Lemmatization\n","    stemmed_words = [stemmer.stem(word) for word in filtered_words]\n","    lemmatized_words = [lemmatizer.lemmatize(word) for word in stemmed_words]\n","\n","    # Reconstruct the cleaned text\n","    cleaned_text = ' '.join(lemmatized_words)\n","\n","    return cleaned_text\n","\n","df['cleaned_text'] = df['text'].apply(preprocess_text)"],"metadata":{"id":"NjnmipZgt4qW","executionInfo":{"status":"ok","timestamp":1696574381316,"user_tz":-360,"elapsed":1507,"user":{"displayName":"Suraia Jabeen","userId":"07369339192617605376"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["df = df.replace([np.inf, -np.inf], np.nan).fillna(99999)\n","df.replace([np.inf, -np.inf], np.nan).dropna()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"HanGynJGt_XT","executionInfo":{"status":"ok","timestamp":1696574389503,"user_tz":-360,"elapsed":824,"user":{"displayName":"Suraia Jabeen","userId":"07369339192617605376"}},"outputId":"ffaefe00-bc2d-491f-b327-5e8d318a9927"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   text sentiment  \\\n","0     b'@SmurphySuzanne @Sunderland_GM And more coun...         1   \n","1     b'RT @TatasenkoMana: This Method suicide 18 Da...         1   \n","2     b'RT @ennui365: Why in the name of Vince Foste...         1   \n","3     b'@Alan_G_Smith_BC @diana_murphy613 @JustinTru...         0   \n","4     b\"RT @sidhant: Turkey's mega Antalya Diplomati...         0   \n","...                                                 ...       ...   \n","1235            I am tired of being weak and destroyed.         1   \n","1236    Every religion fights a final, worldwide cru...         1   \n","1237                 should i stop wanting to be happy?         1   \n","1238    I will spend the coming 207 days combing thr...         0   \n","1239          The Myth of Tiny Radical Muslim Minority\"         0   \n","\n","                                           cleaned_text  \n","0     b smurphysuzann countri align russia china nex...  \n","1     tatasenkomana method suicid 18 dazai explain o...  \n","2     ennui365 name vinc foster heard sinc august fo...  \n","3               b justintrudeau one drive someon suicid  \n","4     b rt sidhant turkey mega antalya diplomat foru...  \n","...                                                 ...  \n","1235                                  tire weak destroy  \n","1236  everi religion fight final worldwid crusad dea...  \n","1237                                    stop want happi  \n","1238  spend come 207 day comb scientif articl compil...  \n","1239                       myth tini radic muslim minor  \n","\n","[1240 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-22b4b698-290a-42c0-9486-ee5d056febc1\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","      <th>cleaned_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>b'@SmurphySuzanne @Sunderland_GM And more coun...</td>\n","      <td>1</td>\n","      <td>b smurphysuzann countri align russia china nex...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>b'RT @TatasenkoMana: This Method suicide 18 Da...</td>\n","      <td>1</td>\n","      <td>tatasenkomana method suicid 18 dazai explain o...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>b'RT @ennui365: Why in the name of Vince Foste...</td>\n","      <td>1</td>\n","      <td>ennui365 name vinc foster heard sinc august fo...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>b'@Alan_G_Smith_BC @diana_murphy613 @JustinTru...</td>\n","      <td>0</td>\n","      <td>b justintrudeau one drive someon suicid</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>b\"RT @sidhant: Turkey's mega Antalya Diplomati...</td>\n","      <td>0</td>\n","      <td>b rt sidhant turkey mega antalya diplomat foru...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1235</th>\n","      <td>I am tired of being weak and destroyed.</td>\n","      <td>1</td>\n","      <td>tire weak destroy</td>\n","    </tr>\n","    <tr>\n","      <th>1236</th>\n","      <td>Every religion fights a final, worldwide cru...</td>\n","      <td>1</td>\n","      <td>everi religion fight final worldwid crusad dea...</td>\n","    </tr>\n","    <tr>\n","      <th>1237</th>\n","      <td>should i stop wanting to be happy?</td>\n","      <td>1</td>\n","      <td>stop want happi</td>\n","    </tr>\n","    <tr>\n","      <th>1238</th>\n","      <td>I will spend the coming 207 days combing thr...</td>\n","      <td>0</td>\n","      <td>spend come 207 day comb scientif articl compil...</td>\n","    </tr>\n","    <tr>\n","      <th>1239</th>\n","      <td>The Myth of Tiny Radical Muslim Minority\"</td>\n","      <td>0</td>\n","      <td>myth tini radic muslim minor</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1240 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22b4b698-290a-42c0-9486-ee5d056febc1')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-22b4b698-290a-42c0-9486-ee5d056febc1 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-22b4b698-290a-42c0-9486-ee5d056febc1');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-05d7bdad-9d55-49bc-94e6-a9e97dbfd497\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-05d7bdad-9d55-49bc-94e6-a9e97dbfd497')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-05d7bdad-9d55-49bc-94e6-a9e97dbfd497 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# Split the data into features (X) and labels (y)\n","X = df['cleaned_text']\n","y = df['sentiment'] # Replace 'Class' with your target column name\n","y = y.tolist()"],"metadata":{"id":"dVMYv53VuEA5","executionInfo":{"status":"ok","timestamp":1696574393493,"user_tz":-360,"elapsed":23,"user":{"displayName":"Suraia Jabeen","userId":"07369339192617605376"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler #fixed import\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"Zk0fGOXLuHhr","executionInfo":{"status":"ok","timestamp":1696574397064,"user_tz":-360,"elapsed":9,"user":{"displayName":"Suraia Jabeen","userId":"07369339192617605376"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","# Assuming X and y are lists\n","X_train = np.array(X).reshape(-1, 1)\n","y_train = np.array(y).reshape(-1, 1)\n"],"metadata":{"id":"2Up1bfIgA5-y","executionInfo":{"status":"ok","timestamp":1696574399991,"user_tz":-360,"elapsed":19,"user":{"displayName":"Suraia Jabeen","userId":"07369339192617605376"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Convert elements in X_train to strings if they are not already\n","X_train = [str(text) for text in X_train]\n","\n","# Tokenize the cleaned text for Word2Vec\n","tokenized_text = [nltk.word_tokenize(text) for text in X_train]\n","\n"],"metadata":{"id":"ZG7sSCBKuK0C","executionInfo":{"status":"ok","timestamp":1696574403971,"user_tz":-360,"elapsed":25,"user":{"displayName":"Suraia Jabeen","userId":"07369339192617605376"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Train Word2Vec embeddings (you can adjust the parameters)\n","word2vec_model = models.Word2Vec(tokenized_text, vector_size=100, window=5, min_count=1, sg=0)"],"metadata":{"id":"VPa1H2G2uNsB","executionInfo":{"status":"ok","timestamp":1696574407509,"user_tz":-360,"elapsed":727,"user":{"displayName":"Suraia Jabeen","userId":"07369339192617605376"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Create Word2Vec vectors for the training data\n","X_train_word2vec = np.array([np.mean([word2vec_model.wv[word] for word in text if word in word2vec_model.wv], axis=0) for text in tokenized_text])"],"metadata":{"id":"ieT0MgF6uQ1r","executionInfo":{"status":"ok","timestamp":1696574410545,"user_tz":-360,"elapsed":8,"user":{"displayName":"Suraia Jabeen","userId":"07369339192617605376"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Tokenize and create Word2Vec vectors for the test data\n","tokenized_test = [nltk.word_tokenize(text) for text in X_test]\n","X_test_word2vec = np.array([np.mean([word2vec_model.wv[word] for word in text if word in word2vec_model.wv], axis=0) for text in tokenized_test])"],"metadata":{"id":"Jgf6-aP6623H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696574414665,"user_tz":-360,"elapsed":956,"user":{"displayName":"Suraia Jabeen","userId":"07369339192617605376"}},"outputId":"e4d0a015-dbc9-4f08-abfe-b617d1e21b2c"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n","  return _methods._mean(a, axis=axis, dtype=dtype,\n","/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n","<ipython-input-12-f3696ed85135>:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  X_test_word2vec = np.array([np.mean([word2vec_model.wv[word] for word in text if word in word2vec_model.wv], axis=0) for text in tokenized_test])\n"]}]},{"cell_type":"code","source":["# Assuming X_train_word2vec and X_test_word2vec are lists\n","X_train_word2vec = np.array(X_train_word2vec)\n","X_test_word2vec = np.array(X_test_word2vec)"],"metadata":{"id":"W9hf3BXmdQQW","executionInfo":{"status":"ok","timestamp":1696574418576,"user_tz":-360,"elapsed":7,"user":{"displayName":"Suraia Jabeen","userId":"07369339192617605376"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Check the shapes of your arrays\n","print(X_train_word2vec.shape)\n","print(X_test_word2vec.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WImpqjQHdTiv","executionInfo":{"status":"ok","timestamp":1696574421895,"user_tz":-360,"elapsed":20,"user":{"displayName":"Suraia Jabeen","userId":"07369339192617605376"}},"outputId":"3e006fd9-dc57-4dfa-c80a-9fee63a2353c"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["(1240, 100)\n","(248,)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","# Define the embedding dimension based on your Word2Vec model\n","embedding_dim = word2vec_model.vector_size\n","\n","# Average Word2Vec embeddings for each document in the training and test sets\n","X_train_word2vec_avg = []\n","for doc in tokenized_text:\n","    embeddings = [word2vec_model.wv[word] for word in doc if word in word2vec_model.wv]\n","    if embeddings:\n","        avg_embedding = np.mean(embeddings, axis=0)\n","    else:\n","        avg_embedding = np.zeros(embedding_dim)  # Use zeros for documents with no valid words\n","    X_train_word2vec_avg.append(avg_embedding)\n","\n","X_train_word2vec_avg = np.array(X_train_word2vec_avg)\n","\n","# Tokenize and create Word2Vec vectors for the test data\n","tokenized_test = [nltk.word_tokenize(text) for text in X_test]\n","X_test_word2vec_avg = []\n","for doc in tokenized_test:\n","    embeddings = [word2vec_model.wv[word] for word in doc if word in word2vec_model.wv]\n","    if embeddings:\n","        avg_embedding = np.mean(embeddings, axis=0)\n","    else:\n","        avg_embedding = np.zeros(embedding_dim)  # Use zeros for documents with no valid words\n","    X_test_word2vec_avg.append(avg_embedding)\n","\n","X_test_word2vec_avg = np.array(X_test_word2vec_avg)\n"],"metadata":{"id":"ajCIq_Red-ll","executionInfo":{"status":"ok","timestamp":1696574428637,"user_tz":-360,"elapsed":715,"user":{"displayName":"Suraia Jabeen","userId":"07369339192617605376"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Import Logistic Regression\n","from sklearn.linear_model import LogisticRegression\n","\n","# Create and train a Logistic Regression classifier\n","logistic_classifier = LogisticRegression(max_iter=1000, random_state=42)\n","logistic_classifier.fit(X_train_word2vec_avg, y_train)\n","\n","# Predict on the test data\n","y_pred = logistic_classifier.predict(X_test_word2vec_avg)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","report = classification_report(y_test, y_pred)\n","\n","# Print the evaluation results\n","print(\"Test Accuracy:\", accuracy)\n","print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n","print(\"\\nClassification Report:\\n\", report)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hCyXO7vk64K0","executionInfo":{"status":"ok","timestamp":1696574455537,"user_tz":-360,"elapsed":658,"user":{"displayName":"Suraia Jabeen","userId":"07369339192617605376"}},"outputId":"6e7567c9-0526-44c1-ca5d-baf200533af6"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.6532258064516129\n","\n","Confusion Matrix:\n"," [[  0  12  47]\n"," [  0  22  27]\n"," [  0   0 140]]\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00        59\n","           1       0.65      0.45      0.53        49\n","       99999       0.65      1.00      0.79       140\n","\n","    accuracy                           0.65       248\n","   macro avg       0.43      0.48      0.44       248\n","weighted avg       0.50      0.65      0.55       248\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]}]}